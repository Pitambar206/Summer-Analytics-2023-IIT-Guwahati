# Summer-Analytics-2023-IIT-Guwahati
 The course spanned over 6 weeks and was power packed with the concepts and fundamentals of Data Science, Machine Learning, and Deep Learning. The Capstone Hackathon at 
 the end enabled me to test the acquired skills hands-on. All the effort was worth it!

An outline of the week-wise graded and ungraded assignments:

## Week-1: Introduction to Python & Python Libraries
The topics under Week-1 included Basic Python Programming, Data Analysis with NumPy and Pandas, Visualizations with Matplotlib and Seaborn, Data Types in Statistics, Measures of Central Tendency, Range, Standard Deviation, Box Plots and Outliers.

## Ungraded Assignments:
  1: Performing and implementing basic Exploratory Data Analysis functions and techniques on a dataset using Pandas.

  2: Performing and implementing basic Exploratory Data Analysis functions and techniques on a dataset using NumPy and Pandas.

## Graded Assignment:
Performing and implementing basic Exploratory Data Analysis functions and techniques on a dataset using NumPy, Pandas and Seaborn.


## Week-2: Machine Learning Algorithms*

Week-2 covered the concepts of Outlier Analysis, Handling Missing Values, introduction to Supervised, Unsupervised and Reinforcement Learning, Linear Regression with One and Multiple Variables with and without Scikit-Learn, and Logistic Regression with and without Scikit-Learn.

## Ungraded Assignment:
Creating basic Linear and Logistic Regression models and finding the Mean Squared Error and Accuracy score after applying Square Root Transformation on a skewed dataset.

##Graded Assignment:
Implementing the Linear Regression algorithm for prediction and computing the Cost Function which is optimised by Gradient Descent.


Week-3: Model Tuning
The contents of Week-3 spanned over Bias-Variance Tradeoff, L1/Lasso and L2/Ridge Regularization, Support Vector Machine, Feature Transformation & Scaling, Label Encoding and One-Hot Encoding, Evaluation Metrics viz. R2 Score, Adjusted R2 Score, F1 Score, Precision, Recall, Accuracy, etc., and Visual Evaluation Metrics viz. Confusion Matrix and AUC-ROC Curve.

Ungraded Assignment:
Tuning a basic Linear Regression model by Filling Null and NaN values, Scaling, Encoding, and Transforming Features, implementing L1 and L2 Regularization (Lasso and Ridge Regression) and Cross Validation, and finding and calculating R2 score, Mean Absolute Error and Mean Squared Error.

Graded Assignment:
Predicting the class of the dependent variable using different algorithms, tuning the hyperparameters to obtain better results, and evaluating through various evaluation metrics.


Week-4: Tree-Based Algorithms
In Week-4, we learnt about Decision Trees, Random Forests, Gradient Boosting, and the XGBoost, AdaBoost, CatBoost and LightGBM algorithms.
